---
title: "Financial Time Series"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

We have defined several types of financial data in `02-Data`. So far, we have explored a particular type of financial data, that is, credit card fraud data (see `03-CreditCardFraud`). We also provide an exploration of another type: financial time series. In particular, we use the sequential stock prices of [Apple](https://www.apple.com/uk/) (an American multinational corporation and technology company) over a period of time forms a financial time series. Such financial time series exhibit distinct features such as volatility, which necessitate different methods to analysis of non-financial time series. Understanding the features of time series and techniques for their analysis is crucial to areas such as quant finance, and can help make informed investment decisions and assess market dynamics.

# Requirements

Some packages are used to facilitate tasks. These can be installed if needed by running the code chunk below.

```{r requirements}
# List of required packages
required_packages <- c("quantmod", "ggplot2", "gridExtra", "zoo")

# Function to check if packages are installed
new_packages <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]

# Install missing packages
if(length(new_packages)) install.packages(new_packages)

# Load required packages
lapply(required_packages, library, character.only = TRUE)
```

# Loading data

We fetch the stock price data of Apple from the Yahoo Finance API (application interface). We chose this data as it can easily be accessed using the Yahoo Finance API and is an example of a financial time series.


Check https://bookdown.org/compfinezbook/introcompfinr/ReturnCalculationsR.html

```{r}
# Get historical stock data for Apple (AAPL) in xts format
library(quantmod) # Get data from the Yahoo Finance API
getSymbols("AAPL", src = "yahoo", from = "2020-01-01", to = "2024-01-01")

str(AAPL)
```

We see that the data comes in the form of an `xts` object, meaning "eXtensible Time Series". This is also an `R` package (run `vignette('xts')` for more information) designed for handling and analyzing time series data. An xts object is a type of data structure that extends the `zoo` class, allowing users to work with time series data more effectively. Due to time constraints, we do not explore this much further, and direct the reader to a tutorial such as [1]. 

# Exploratory Data Analysis

We begin with EDA. WE first look at the variables present in the data. The variables present in the data are shown in the table below.

| Variable Name | Description                                         |
|---------------|-----------------------------------------------------|
| Date          | The date of the stock price observation.           |
| Open          | The stock price at market open.                    |
| High          | The highest stock price during the trading day.    |
| Low           | The lowest stock price during the trading day.     |
| Close         | The stock price at market close.                   |
| Volume        | The total number of shares traded during the day.  |
| Adjusted      | The adjusted closing price, accounting for splits and dividends. |

We now show some quantitative aspects of the dataset.

```{r}
head(AAPL)
summary(AAPL)
```

We can see that the data was collected from times January 1 2020 to December 29 2023.  The volume seems to be quite positively skewed with a maximum of 426.51 million and a minimum of 24.0483 million. The opening, high, low and closing and adjusted closing prices seem to be similar in their means and quantiles. To explore this further, we looked at the shape of the histograms of the prices.


```{r}
library(ggplot2) # To make plots

# Function to plot histograms
plot_histogram <- function(data, column_name) {
  ggplot(data, aes_string(x = column_name)) +
    geom_histogram(binwidth = 10, fill = "blue", color = "black", alpha = 0.7) +
    labs(title = paste("Histogram of", column_name), x = column_name, y = "Frequency") +
    theme_minimal()
}

# Create a list of columns to plot
columns_to_plot <- c("AAPL.Open", "AAPL.High", "AAPL.Low", "AAPL.Close", "AAPL.Adjusted")

# Plot histograms for each column
for (col in columns_to_plot) {
  print(plot_histogram(AAPL, col))
}
```

As expected, we see that the shapes of the histograms are similar. We however uncover that the prices are bimodal. 

We use line plots to visualise the closing price and trading volume over time. We also use a 30-day moving average for the closing price to understand the trend.

```{r}
library(zoo)          # For rollmean
library(gridExtra)    # For arranging plots

# Calculate 30-Day Moving Average for Closing Price
AAPL$MA30Price <- rollmean(AAPL$AAPL.Close, k = 30, fill = NA, align = "right")

# 1. Plot: Closing Price Over Time
p1 <- ggplot() +
  geom_line(aes(x = index(AAPL), y = coredata(AAPL$AAPL.Close)), color = "blue") +
  geom_line(aes(x = index(AAPL), y = coredata(AAPL$MA30Price)), color = "red") +
  labs(title = "AAPL Closing Price with 30-Day Moving Average", 
       x = "Date", 
       y = "Price") +
  theme_minimal()

# Calculate 30-Day Moving Average for Volume
AAPL$MA30Vol <- rollmean(AAPL$AAPL.Volume, k = 30, fill = NA, align = "right")

# 2. Plot: Volume Over Time
p2 <- ggplot() +
  geom_line(aes(x = index(AAPL), y = coredata(AAPL$AAPL.Volume)), color = "lightblue") +
  geom_line(aes(x = index(AAPL), y = coredata(AAPL$MA30Vol)), color = "grey") +
  labs(title = "AAPL Trading Volume Over Time", 
       x = "Date", 
       y = "Volume") +
  theme_minimal()

# Arrange plots in a grid
gridExtra::grid.arrange(p1, p2, ncol = 1)

```

We see a warning as follows:
`Warning: [38;5;232mRemoved 29 rows containing missing values or values outside the scale range (geom_line()).[39m`

This is because the 30-day moving average will not have values for the first 29 observations, because there are not enough observations at that point to form the 30-day moving average. It is not a cause for concern, but the code was not modified to suppress this warning due to time constraints. 

We can see that the closing price is quite volatile but with an overall increasing trend.  The trading volume seems to be quite volatile as well, having high peaks between 2020 and 2021. We investigate the reason for these peaks. We found that this period coincided with a global pandemic, with a disease called Coronavirus Disease 2019 (COVID-19) affecting the world. On August 19 2020, Apple's market value exceeded 2 trillion US dollars (see a [source here](https://www.atlantis-press.com/article/125966048.pdf)). The trading volume seems to taper off and stabilise after 2021.

# Further Exploration

We follow the literature (see Section 6.1 of Engle [1]) to explore models for financial time series. The quantity that is often modelled is the log-returns. Given the prices $\{P_t\}$, we can compute the log-return $X_t$ at time $t$ using the formula $$X_t = \log \left( \frac{P_t}{P_{t-1}} \right).$$ Note that if we have $N$ values for the price, we will have $N-1$ values for the log-returns. 

We compute and plot the log-returns below. We observe that $\{X_t\}$ has a sample path resembling that of a sequence of uncorrelated random variables with possibly time-varying variance.


```{r}
# Calculate Daily Log Returns directly on the xts object
AAPL$Log_Returns <- diff(log(AAPL$AAPL.Close))

# Plot: Daily Log Returns
p4 <- ggplot() +
  geom_line(aes(x = index(AAPL), y = coredata(AAPL$Log_Returns)), color = "green") +
  labs(title = "AAPL Daily Log Returns", x = "Date", y = "Log Return") +
  theme_minimal()

# Log Returns (X_t)
AAPL$Log_Returns <- diff(log(AAPL$AAPL.Close))
```

The so-called "stylised features" (see [2] for example of the usage of the term) of log-returns include:

1. **Serial Dependence Without Correlation**: No significant autocorrelation is exhibited, but there may still be dependencies. To uncover this, we will consider the autocorrelation function (ACF) plots of $\{X_t\}$, $\{|X_t|\}$ and $\{X_t^2\}$. 

2. **Volatility Clustering**: High-volatility periods tend to be followed by high-volatility periods, and low-volatility periods tend to follow low-volatility periods. This is often visible in returns' time series. We will plot $\{X_t^2\}$ to see this.

3. **Heavy-Tailed Distribution**: Financial returns do not follow a normal distribution. They tend to have heavier tails, meaning extreme events (both positive and negative) occur more frequently than would be expected in a normal distribution. We will uncover this with a quantile-quantile plot.

4. **Leverage Effect**: The market reacts differently to positive and negative news, and this is reflected in the time series. We consider a plot of the quantiles of $|X_t|$ when the previous value of $X_{t-1}$ was negative versus when the when the previous value of $X_{t-1}$ was positive.

Note: The autocorrelation $\rho_k$ of a time series $\{X_t\}$ with $n$ observations at lag \( k \) is given by:

\[
\rho_k = \frac{\sum_{t=k+1}^{n}(X_t - \bar{X})(X_{t-k} - \bar{X})}{\sum_{t=1}^{n}(X_t - \bar{X})^2}.
\]

```{r}
# --- 1. Serial Correlation ---

# Set up the plotting area to display 3 plots side by side
par(mfrow = c(1, 3))  # Set up the plot window to have 1 row and 3 columns

# 1. ACF of X_t (log returns)
acf(AAPL$Log_Returns, na.action = na.omit, main = "ACF of X_t (Log Returns)")

# 2. ACF of |X_t| (absolute log returns)
acf(abs(AAPL$Log_Returns), na.action = na.omit, main = "ACF of |X_t| (Absolute Log Returns)")

# 3. ACF of X_t^2 (squared log returns)
acf(AAPL$Log_Returns^2, na.action = na.omit, main = "ACF of X_t^2 (Squared Log Returns)")

par(mfrow=c(1,1))

# --- 2. Volatility Clustering ---

# Plot X_t^2 (squared returns)
volatility_plot <- ggplot() +
  geom_line(aes(x = index(AAPL), y = coredata(AAPL$Log_Returns^2)), color = "blue") +
  labs(title = "Volatility Clustering: Squared Log Returns", x = "Date", y = "Squared Returns") +
  theme_minimal()

# Print volatility plot
print(volatility_plot)

# --- 3. Heavy-Tailedness ---

# Assuming AAPL data is already loaded and log returns are calculated
AAPL$Log_Returns <- diff(log(AAPL$AAPL.Close))

# Q-Q plot of log returns against a normal distribution
qqnorm(AAPL$Log_Returns, main = "Q-Q Plot: Log Returns vs. Normal Distribution", na.rm = TRUE)
qqline(AAPL$Log_Returns, col = "red", lwd = 2)  # Add a Q-Q line to compare to a normal distribution


# --- 4. Leverage Effect ---

# Assuming AAPL data is already loaded and log returns are calculated
AAPL$Log_Returns <- diff(log(AAPL$AAPL.Close))

# Calculate the absolute log returns
AAPL$Abs_Returns <- abs(AAPL$Log_Returns)

# Lag the returns by 1 period (no need to specify k = 1)
lagged_returns <- lag(AAPL$Log_Returns)

# Subset absolute returns based on lagged returns: |X_t| when X_{t-1} < 0 and |X_t| when X_{t-1} > 0
negative_lag <- AAPL$Abs_Returns[lagged_returns < 0 & !is.na(lagged_returns)]
positive_lag <- AAPL$Abs_Returns[lagged_returns > 0 & !is.na(lagged_returns)]

# Q-Q plot of |X_t| when X_{t-1} < 0 vs |X_t| when X_{t-1} > 0
qqplot(positive_lag, negative_lag,
       main = "Leverage Effect: Q-Q Plot of |X_t|",
       xlab = "|X_t| when X_{t-1} > 0",
       ylab = "|X_t| when X_{t-1} < 0",
       col = "blue", pch = 19)

# Add a 45-degree reference line
abline(0, 1, col = "red", lwd = 2)

```

Notice that there is no persistent autocorrelation in $\{X_t\}$ while the autocorrelation are very persistent for the $\{|X_t|\}$ and $\{X_t^2\}$. For the plot of $\{X_t^2\}$, we can see peaks indicating high volatility being somewhat clustered, showing the volatility clustering. The QQ plot shows that the log returns are heavy tailed. The quantile plot is not symmetric about the diagonal line, showing the leverage effect. 

# Modelling

Modelling this data uses the so-called ARCH models, or auto-regressive conditional heteroskedastic models. This is an advanced topic that would significantly lengthen this document. We refer the reader to Engle [1] for further details on this model. Generalisations such as the GARCH, EGARCH, IGARCH are also used in practice (see [3] for details on GARCH). This would take us too far afield, and would not yield a classification or regression problem.

Indeed, such models are fitted by the methods of quasi-maximum likelihood. While this can be seen as minimizing a loss function (the negative (quasi-)log-likelihood), some may not consider the topic of time series modelling to be a regression problem. It may be noted that time series models do appear under `Appropriate Content` in Assessment 1 [guidance](https://dsbristol.github.io/dst/assets/assessments/Assessment1.pdf) and so this was not a fruitless or irrelevant endeavour.

# Conclusion

We looked at Apple stock data in detail, exploring its structure and uncovering insights into the data. We looked at more advanced features of the data, by exploring the log-returns and looking at its stylised features. We briefly mentioned the methods used to model financial time series and cut the discussion short upon noting that it may be too complicated for analysis.

# References

1. Engle, Robert F. "Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation." Econometrica: Journal of the econometric society (1982): 987-1007.
2. [Lecture Notes on Financial Time Series](https://www.soas.ac.uk/sites/default/files/2023-02/M459_unit-01_sample.pdf): Accessed 9:09 on 27/09/2024.
3. Bollerslev, T. (1986). Generalized autoregressive conditional heteroskedasticity. Journal of Econometrics, 31:307–327.
4. [Apple Hits a $2tn Market Capitalisation](https://www.atlantis-press.com/article/125966048.pdf).